{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1079a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "#need this as we have a lot of columns\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "#hide warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3580b8",
   "metadata": {},
   "source": [
    "### Load in the dataset\n",
    "\n",
    "See the amex_random_forest.ipynb file for EDA and more info regarding the processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e8392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_data.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3b6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by ='S_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55813ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop the ID column and date columns since it wont help out model\n",
    "df.pop('customer_ID')\n",
    "df.pop('S_2')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f82f5",
   "metadata": {},
   "source": [
    "I need to drop the columns up from above which were predominantly NaNs\n",
    " ['D_42', 'D_49', 'D_50', 'D_53', 'D_56', 'S_9', 'B_17', 'D_66', 'D_73', 'D_76', 'D_77', 'R_9', 'D_82', 'B_29', 'D_87', 'D_88', 'D_105', 'D_106', 'R_26', 'D_108', 'D_110', 'D_111', 'B_39', 'B_42', 'D_132', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_142']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "596c556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['D_42', 'D_49', 'D_50', 'D_53', 'D_56', 'S_9', 'B_17', 'D_66', 'D_73', 'D_76', \n",
    "            'D_77', 'R_9', 'D_82', 'B_29', 'D_87', 'D_88', 'D_105', 'D_106', 'R_26', 'D_108',\n",
    "            'D_110', 'D_111', 'B_39', 'B_42', 'D_132', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_142']\n",
    "\n",
    "for i in del_cols: \n",
    "    df.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c0cae",
   "metadata": {},
   "source": [
    "Lets check out the new dimensions of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb794dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 158)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679c5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "#new_cols = [i for i in cols if i not in del_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b620c",
   "metadata": {},
   "source": [
    "B_38 needs to be reindex to start index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c927ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1953232\n",
       "2    1255315\n",
       "0    1160047\n",
       "4     444856\n",
       "3     294917\n",
       "6     259028\n",
       "5     162040\n",
       "Name: B_38, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_38_mapping = {label: idx for idx, label in enumerate(np.unique(df['B_38']))}\n",
    "df['B_38'] = df['B_38'].map(B_38_mapping)\n",
    "\n",
    "#lets confirm it worked\n",
    "df['B_38'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aefb627",
   "metadata": {},
   "source": [
    "Drop the categoricals with negative values, unclear what these signify\n",
    "\n",
    "D_117\n",
    "D_126\n",
    "D_64\n",
    "\n",
    "For D_63, this column need to be one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9132c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.pop('D_117')\n",
    "df.pop('D_126')\n",
    "df.pop('D_64')\n",
    "display(df.columns.get_loc(\"D_63\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631cf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "032e3acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.79 s, sys: 10.2 s, total: 16 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [45])], remainder='passthrough')\n",
    "df = columnTransformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbd4ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the onehot encoded cols need to be standardized as well\n",
    "column_trans = ColumnTransformer([('scaler', StandardScaler(),[0,1,2,3,4,5])],\n",
    "                                   remainder='passthrough') \n",
    "df = column_trans.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cc83d",
   "metadata": {},
   "source": [
    "for all cols which we didnt drop due to our nan thresholds we will impute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ef2cf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.02 s, sys: 12 s, total: 20 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "imp=SimpleImputer(missing_values=np.NaN, strategy='constant', fill_value = -1)\n",
    "df=pd.DataFrame(imp.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b5028ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(col)\n",
    "col.remove('D_63')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "790ac6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['onehot1','onehot2','onehot3','onehot4','onehot5','onehot6']\n",
    "new_cols = one_hot_cols + col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e222992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26850190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "Y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bfc7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle default is True, we set to false to preserve time series ordering\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle = False)\n",
    "\n",
    "# 0.25 x 0.8 = 0.2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25,  shuffle = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d145761",
   "metadata": {},
   "source": [
    "### Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01a857b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #define out input layer\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    #define range of value of nodes to include in our layers\n",
    "    hp_units = hp.Int('units', min_value=500, max_value=1200, step=100)    \n",
    "    \n",
    "    #add full connected layers\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units,\n",
    "                                    name='fc_1', \n",
    "                                    activation='relu'))       \n",
    "              \n",
    "    #dropout regularization technique, randomly sets nodes = 0 at probabilty set by rate\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    \n",
    "    #add full connected layers\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units,\n",
    "                                    name='fc_2', \n",
    "                                    activation='relu'))       \n",
    "              \n",
    "    #dropout regularization technique, randomly sets nodes = 0 at probabilty set by rate\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    \n",
    "    # add the last fully connected layer\n",
    "    # this last layer sets the activation function to \"None\" in order to output the logits \n",
    "    # note that passing activation = \"sigmoid\" will return class memembership probabilities but\n",
    "    # in TensorFlow logits are prefered for numerical stability\n",
    "    # set units=1 to get a single output unit (remember it's a binary classification problem)\n",
    "    model.add(tf.keras.layers.Dense(units=1,\n",
    "                                    name='output_layer',\n",
    "                                    activation=None))\n",
    "    \n",
    "    #define ranges for learning rates\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    #compile it, with optimizer, loss, and accuracy\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #set from_ligits=True because our last layer does not apply sigmoid\n",
    "                  metrics=['accuracy']) \n",
    "                        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4e17d",
   "metadata": {},
   "source": [
    "Now that we have constructed our model, we can hypertune it using the built in tuner from TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cbec74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(nn_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c63a3",
   "metadata": {},
   "source": [
    "Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc327d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231696f",
   "metadata": {},
   "source": [
    "`Tune and find best hyper-parameters`\n",
    "\n",
    "Run the hyperparameter search. The arguments for the search method are the same as those used for tf.keras.model.fit in addition to the callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2504a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [07h 19m 21s]\n",
      "val_accuracy: 0.8371584415435791\n",
      "\n",
      "Best val_accuracy So Far: 0.876420259475708\n",
      "Total elapsed time: 3d 20h 34m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 1100 and the optimal learning rate for the optimizer\n",
      "is 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789098cc",
   "metadata": {},
   "source": [
    "`Train final model with optimal hyperparameters`\n",
    "\n",
    "Now all we have done is find the best hyperparameter for our neural network. The next step is to pull the best hyperparams and then train our final tuned neural network on that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19ff78dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "103715/103715 [==============================] - 393s 4ms/step - loss: 0.2939 - accuracy: 0.8574 - val_loss: 0.2652 - val_accuracy: 0.8782\n",
      "Epoch 2/50\n",
      "103715/103715 [==============================] - 1344s 13ms/step - loss: 0.2851 - accuracy: 0.8612 - val_loss: 0.2632 - val_accuracy: 0.8806\n",
      "Epoch 3/50\n",
      "103715/103715 [==============================] - 401s 4ms/step - loss: 0.2821 - accuracy: 0.8630 - val_loss: 0.2608 - val_accuracy: 0.8761\n",
      "Epoch 4/50\n",
      "103715/103715 [==============================] - 400s 4ms/step - loss: 0.2796 - accuracy: 0.8645 - val_loss: 0.2605 - val_accuracy: 0.8803\n",
      "Epoch 5/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2772 - accuracy: 0.8659 - val_loss: 0.2577 - val_accuracy: 0.8813\n",
      "Epoch 6/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2747 - accuracy: 0.8676 - val_loss: 0.2563 - val_accuracy: 0.8810\n",
      "Epoch 7/50\n",
      "103715/103715 [==============================] - 385s 4ms/step - loss: 0.2723 - accuracy: 0.8691 - val_loss: 0.2565 - val_accuracy: 0.8834\n",
      "Epoch 8/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2693 - accuracy: 0.8708 - val_loss: 0.2555 - val_accuracy: 0.8818\n",
      "Epoch 9/50\n",
      "103715/103715 [==============================] - 387s 4ms/step - loss: 0.2675 - accuracy: 0.8725 - val_loss: 0.2538 - val_accuracy: 0.8845\n",
      "Epoch 10/50\n",
      "103715/103715 [==============================] - 404s 4ms/step - loss: 0.2646 - accuracy: 0.8741 - val_loss: 0.2543 - val_accuracy: 0.8847\n",
      "Epoch 11/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2627 - accuracy: 0.8757 - val_loss: 0.2516 - val_accuracy: 0.8828\n",
      "Epoch 12/50\n",
      "103715/103715 [==============================] - 389s 4ms/step - loss: 0.2607 - accuracy: 0.8775 - val_loss: 0.2498 - val_accuracy: 0.8858\n",
      "Epoch 13/50\n",
      "103715/103715 [==============================] - 390s 4ms/step - loss: 0.2575 - accuracy: 0.8791 - val_loss: 0.2495 - val_accuracy: 0.8871\n",
      "Epoch 14/50\n",
      "103715/103715 [==============================] - 391s 4ms/step - loss: 0.2551 - accuracy: 0.8808 - val_loss: 0.2488 - val_accuracy: 0.8859\n",
      "Epoch 15/50\n",
      "103715/103715 [==============================] - 390s 4ms/step - loss: 0.2529 - accuracy: 0.8822 - val_loss: 0.2511 - val_accuracy: 0.8878\n",
      "Epoch 16/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2514 - accuracy: 0.8839 - val_loss: 0.2477 - val_accuracy: 0.8865\n",
      "Epoch 17/50\n",
      "103715/103715 [==============================] - 393s 4ms/step - loss: 0.2484 - accuracy: 0.8852 - val_loss: 0.2475 - val_accuracy: 0.8834\n",
      "Epoch 18/50\n",
      "103715/103715 [==============================] - 400s 4ms/step - loss: 0.2458 - accuracy: 0.8866 - val_loss: 0.2466 - val_accuracy: 0.8889\n",
      "Epoch 19/50\n",
      "103715/103715 [==============================] - 388s 4ms/step - loss: 0.2437 - accuracy: 0.8880 - val_loss: 0.2464 - val_accuracy: 0.8911\n",
      "Epoch 20/50\n",
      "103715/103715 [==============================] - 23376s 225ms/step - loss: 0.2411 - accuracy: 0.8893 - val_loss: 0.2460 - val_accuracy: 0.8906\n",
      "Epoch 21/50\n",
      "103715/103715 [==============================] - 54652s 527ms/step - loss: 0.2408 - accuracy: 0.8905 - val_loss: 0.2448 - val_accuracy: 0.8919\n",
      "Epoch 22/50\n",
      "103715/103715 [==============================] - 408s 4ms/step - loss: 0.2402 - accuracy: 0.8915 - val_loss: 0.2449 - val_accuracy: 0.8912\n",
      "Epoch 23/50\n",
      "103715/103715 [==============================] - 404s 4ms/step - loss: 0.2376 - accuracy: 0.8926 - val_loss: 0.2441 - val_accuracy: 0.8891\n",
      "Epoch 24/50\n",
      "103715/103715 [==============================] - 393s 4ms/step - loss: 0.2356 - accuracy: 0.8935 - val_loss: 0.2431 - val_accuracy: 0.8921\n",
      "Epoch 25/50\n",
      "103715/103715 [==============================] - 405s 4ms/step - loss: 0.2346 - accuracy: 0.8944 - val_loss: 0.2416 - val_accuracy: 0.8925\n",
      "Epoch 26/50\n",
      "103715/103715 [==============================] - 386s 4ms/step - loss: 0.2322 - accuracy: 0.8953 - val_loss: 0.2426 - val_accuracy: 0.8948\n",
      "Epoch 27/50\n",
      "103715/103715 [==============================] - 392s 4ms/step - loss: 0.2348 - accuracy: 0.8964 - val_loss: 0.2424 - val_accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "103715/103715 [==============================] - 393s 4ms/step - loss: 0.2304 - accuracy: 0.8970 - val_loss: 0.2433 - val_accuracy: 0.8936\n",
      "Epoch 29/50\n",
      "103715/103715 [==============================] - 396s 4ms/step - loss: 0.2325 - accuracy: 0.8979 - val_loss: 0.2412 - val_accuracy: 0.8954\n",
      "Epoch 30/50\n",
      "103715/103715 [==============================] - 385s 4ms/step - loss: 0.2269 - accuracy: 0.8985 - val_loss: 0.2409 - val_accuracy: 0.8957\n",
      "Epoch 31/50\n",
      "103715/103715 [==============================] - 384s 4ms/step - loss: 0.2259 - accuracy: 0.8992 - val_loss: 0.2412 - val_accuracy: 0.8948\n",
      "Epoch 32/50\n",
      "103715/103715 [==============================] - 396s 4ms/step - loss: 0.2252 - accuracy: 0.9000 - val_loss: 0.2409 - val_accuracy: 0.8989\n",
      "Epoch 33/50\n",
      "103715/103715 [==============================] - 389s 4ms/step - loss: 0.2237 - accuracy: 0.9005 - val_loss: 0.2404 - val_accuracy: 0.8948\n",
      "Epoch 34/50\n",
      "103715/103715 [==============================] - 392s 4ms/step - loss: 0.2241 - accuracy: 0.9010 - val_loss: 0.2390 - val_accuracy: 0.8965\n",
      "Epoch 35/50\n",
      "103715/103715 [==============================] - 394s 4ms/step - loss: 0.2236 - accuracy: 0.9015 - val_loss: 0.2390 - val_accuracy: 0.8961\n",
      "Epoch 36/50\n",
      "103715/103715 [==============================] - 390s 4ms/step - loss: 0.2227 - accuracy: 0.9022 - val_loss: 0.2393 - val_accuracy: 0.8951\n",
      "Epoch 37/50\n",
      "103715/103715 [==============================] - 385s 4ms/step - loss: 0.2226 - accuracy: 0.9026 - val_loss: 0.2371 - val_accuracy: 0.8963\n",
      "Epoch 38/50\n",
      "103715/103715 [==============================] - 701s 7ms/step - loss: 0.2192 - accuracy: 0.9031 - val_loss: 0.2382 - val_accuracy: 0.8987\n",
      "Epoch 39/50\n",
      "103715/103715 [==============================] - 406s 4ms/step - loss: 0.2190 - accuracy: 0.9038 - val_loss: 0.2379 - val_accuracy: 0.8993\n",
      "Epoch 40/50\n",
      "103715/103715 [==============================] - 403s 4ms/step - loss: 0.2210 - accuracy: 0.9042 - val_loss: 0.2410 - val_accuracy: 0.8987\n",
      "Epoch 41/50\n",
      "103715/103715 [==============================] - 387s 4ms/step - loss: 0.2175 - accuracy: 0.9045 - val_loss: 0.2365 - val_accuracy: 0.9013\n",
      "Epoch 42/50\n",
      "103715/103715 [==============================] - 385s 4ms/step - loss: 0.2177 - accuracy: 0.9052 - val_loss: 0.2362 - val_accuracy: 0.8981\n",
      "Epoch 43/50\n",
      "103715/103715 [==============================] - 406s 4ms/step - loss: 0.2184 - accuracy: 0.9052 - val_loss: 0.2417 - val_accuracy: 0.9017\n",
      "Epoch 44/50\n",
      "103715/103715 [==============================] - 391s 4ms/step - loss: 0.2178 - accuracy: 0.9055 - val_loss: 0.2389 - val_accuracy: 0.9012\n",
      "Epoch 45/50\n",
      "103715/103715 [==============================] - 397s 4ms/step - loss: 0.2149 - accuracy: 0.9061 - val_loss: 0.2343 - val_accuracy: 0.8997\n",
      "Epoch 46/50\n",
      "103715/103715 [==============================] - 392s 4ms/step - loss: 0.2145 - accuracy: 0.9065 - val_loss: 0.2371 - val_accuracy: 0.9018\n",
      "Epoch 47/50\n",
      "103715/103715 [==============================] - 399s 4ms/step - loss: 0.2128 - accuracy: 0.9067 - val_loss: 0.2374 - val_accuracy: 0.9007\n",
      "Epoch 48/50\n",
      "103715/103715 [==============================] - 49183s 474ms/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.2369 - val_accuracy: 0.9014\n",
      "Epoch 49/50\n",
      "103715/103715 [==============================] - 15262s 147ms/step - loss: 0.2155 - accuracy: 0.9076 - val_loss: 0.2376 - val_accuracy: 0.9013\n",
      "Epoch 50/50\n",
      "103715/103715 [==============================] - 395s 4ms/step - loss: 0.2146 - accuracy: 0.9078 - val_loss: 0.2374 - val_accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=50, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "350c40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 50\n"
     ]
    }
   ],
   "source": [
    "#Lets find the best epoch\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f6786",
   "metadata": {},
   "source": [
    "Now that we know what the best number of epochs are, we can train our model with that number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1579b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64393dc",
   "metadata": {},
   "source": [
    "Since we already trained our model on the 50 epochs, we can just use that instead of training it again for 50 epochs. Given 50 epochs provided the best validation accuracy, next time we could increase the epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59566858",
   "metadata": {},
   "source": [
    "`Evaluate on Test Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaf1c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34572/34572 [==============================] - 41s 1ms/step - loss: 0.3084 - accuracy: 0.8956\n",
      "[test loss, test accuracy]: [0.30836179852485657, 0.8955708742141724]\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate(X_test, Y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b106ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
